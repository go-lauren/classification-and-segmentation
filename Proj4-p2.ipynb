{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Proj4-p2","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNaZDCtmll4VegZ4g55z0y/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"5UIHEL8H5PCF","colab_type":"code","colab":{}},"source":["\"\"\"\n","File setup\n","\"\"\"\n","# from google.colab import drive\n","# drive.mount(\"/content/drive/\")\n","# import sys\n","# sys.path.append('/content/drive/My Drive/Colab Notebooks/Proj4/')\n","# import os\n","# os.chdir('/content/drive/My Drive/Colab Notebooks/Proj4/')\n","\n","# !pip install -r ./requirements.txt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tHfbez6ocbrj","colab_type":"code","colab":{}},"source":["\"\"\"\n","Import packages\n","\"\"\"\n","import time\n","\n","import cv2\n","import matplotlib.pyplot as plt\n","from matplotlib import colors\n","import numpy as np\n","import png\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","from colormap.colors import Color, hex2rgb\n","from sklearn.metrics import average_precision_score as ap_score\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, models, transforms\n","from tqdm import tqdm\n","import tensorflow as tf\n","\n","from dataset import FacadeDataset"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mH0J2CMp7Bk9","colab_type":"code","colab":{}},"source":["def save_label(label, path):\n","    '''\n","    Function for ploting labels.\n","    '''\n","    colormap = [\n","        '#000000',\n","        '#0080FF',\n","        '#80FF80',\n","        '#FF8000',\n","        '#FF0000',\n","    ]\n","    assert(np.max(label)<len(colormap))\n","    colors = [hex2rgb(color, normalise=False) for color in colormap]\n","    w = png.Writer(label.shape[1], label.shape[0], palette=colors, bitdepth=4)\n","    with open(path, 'wb') as f:\n","        w.write(f, label)\n","\n","def train(trainloader, net, criterion, optimizer, device, epoch):\n","    '''\n","    Function for training.\n","    '''\n","    start = time.time()\n","    running_loss = 0.0\n","    net = net.train()\n","    for images, labels in tqdm(trainloader, position=0, leave=True):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        optimizer.zero_grad()\n","        output = net(images)\n","        loss = criterion(output, labels)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss = loss.item()\n","    end = time.time()\n","    print('[epoch %d] loss: %.3f elapsed time %.3f' %\n","          (epoch, running_loss, end-start))\n","\n","def test(testloader, net, criterion, device):\n","    '''\n","    Function for testing.\n","    '''\n","    losses = 0.\n","    cnt = 0\n","    with torch.no_grad():\n","        net = net.eval()\n","        for images, labels in tqdm(testloader, position=0, leave=True):\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            output = net(images)\n","            loss = criterion(output, labels)\n","            losses += loss.item()\n","            cnt += 1\n","    print(losses / cnt)\n","    return (losses/cnt)\n","\n","\n","def cal_AP(testloader, net, criterion, device):\n","    '''\n","    Calculate Average Precision\n","    '''\n","    losses = 0.\n","    cnt = 0\n","    with torch.no_grad():\n","        net = net.eval()\n","        preds = [[] for _ in range(5)]\n","        heatmaps = [[] for _ in range(5)]\n","        for images, labels in tqdm(testloader, position=0, leave=True):\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            output = net(images).cpu().numpy()\n","            for c in range(5):\n","                preds[c].append(output[:, c].reshape(-1))\n","                heatmaps[c].append(labels[:, c].cpu().numpy().reshape(-1))\n","\n","        aps = []\n","        for c in range(5):\n","            preds[c] = np.concatenate(preds[c])\n","            heatmaps[c] = np.concatenate(heatmaps[c])\n","            if heatmaps[c].max() == 0:\n","                ap = float('nan')\n","            else:\n","                ap = ap_score(heatmaps[c], preds[c])\n","                aps.append(ap)\n","            print(\"AP = {}\".format(ap))\n","    return None\n","\n","\n","def get_result(testloader, net, device, folder='output_train'):\n","    result = []\n","    cnt = 1\n","    with torch.no_grad():\n","        net = net.eval()\n","        cnt = 0\n","        for images, labels in tqdm(testloader, position=0, leave=True):\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            output = net(images)[0].cpu().numpy()\n","            c, h, w = output.shape\n","            assert(c == N_CLASS)\n","            y = np.zeros((h,w)).astype('uint8')\n","            for i in range(N_CLASS):\n","                mask = output[i]>0.7\n","                y[mask] = i\n","            gt = labels.cpu().data.numpy().squeeze(0).astype('uint8')\n","            save_label(y, './{}/y{}.png'.format(folder, cnt))\n","            save_label(gt, './{}/gt{}.png'.format(folder, cnt))\n","            plt.imsave(\n","                './{}/x{}.png'.format(folder, cnt),\n","                ((images[0].cpu().data.numpy()+1)*128).astype(np.uint8).transpose(1,2,0))\n","\n","            cnt += 1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SQhK3u2h6E_8","colab_type":"code","cellView":"code","colab":{}},"source":["\"\"\"\n","Neural network hyperparameters and layers\n","\"\"\"\n","N_CLASS = 5\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.n_class = N_CLASS\n","        self.layers = nn.Sequential(\n","            nn.Conv2d(3, 32, 3, padding=1),\n","            nn.BatchNorm2d(32, momentum=0.01),\n","            nn.ReLU(),\n","            nn.Conv2d(32, 64, 3, padding=1),\n","            nn.BatchNorm2d(64, momentum=0.01),\n","            nn.ReLU(),\n","            nn.Conv2d(64, 128, 3, padding=1),\n","            nn.BatchNorm2d(128, momentum=0.01),\n","            nn.ReLU(),\n","            nn.Conv2d(128, 64, 3, padding=1),\n","            nn.BatchNorm2d(64, momentum=0.01),\n","            nn.ReLU(),\n","            nn.Conv2d(64, 32, 3, padding=1),\n","            nn.BatchNorm2d(32, momentum=0.01),\n","            nn.Conv2d(32, 5, 3, padding=1),\n","            nn.BatchNorm2d(5, momentum=0.01),\n","            nn.ReLU()\n","        )\n","\n","    def forward(self, x):\n","        x = self.layers(x)\n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SSrDUhM17Pw9","colab_type":"code","colab":{}},"source":["\"\"\"\n","Set up datasets: TRAINING, EVAL, TEST\n","\"\"\"\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","train_data = FacadeDataset(flag='train', data_range=(0,800), onehot=False)\n","train_loader = DataLoader(train_data, batch_size=4)\n","test_data = FacadeDataset(flag='test_dev', data_range=(0,114), onehot=False)\n","test_loader = DataLoader(test_data, batch_size=1)\n","evaluation_data = FacadeDataset(flag='train', data_range=(800,906), onehot=False)\n","evaluation_loader = DataLoader(evaluation_data, batch_size=1)\n","ap_data = FacadeDataset(flag='test_dev', data_range=(0,114), onehot=True)\n","ap_loader = DataLoader(ap_data, batch_size=4)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r4AfdKQTgSjQ","colab_type":"code","colab":{}},"source":["name = 'retry_net'\n","net = Net().to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(net.parameters(), 1e-3, weight_decay=1e-5)\n","training_loss = np.zeros(100)\n","validation_loss = np.zeros(100)\n","print('\\nStart training')\n","for epoch in range(0, 30):\n","    print('-----------------Epoch = %d-----------------' % (epoch+1))\n","    train(train_loader, net, criterion, optimizer, device, epoch+1)\n","    training_loss[epoch] = test(train_loader, net, criterion, device)\n","    validation_loss[epoch] = test(evaluation_loader, net, criterion, device)\n","\n","print('\\nFinished Training, Testing on test set')\n","test(test_loader, net, criterion, device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"maUiM2JEAXHj","colab_type":"code","colab":{}},"source":["print('\\nGenerating Unlabeled Result')\n","result = get_result(test_loader, net, device, folder='output_test')\n","torch.save(net.state_dict(), './models/model_{}.pth'.format(name))\n","cal_AP(ap_loader, net, criterion, device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wGC_t2PUDdW2","colab_type":"code","colab":{}},"source":["epochs = np.linspace(1, 30, 30)\n","fig = plt.figure(figsize=(10,5))\n","plt.plot(epochs, training_loss[:30], label=\"Training\")\n","plt.plot(epochs, validation_loss[:30], label=\"Validation\")\n","plt.title(\"Training vs Validation Loss\")\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Average Loss\")\n","fig.legend()\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nTBc8Dvsn2kU","colab_type":"code","colab":{}},"source":["img = plt.imread(\"./london.JPG\")\n","img = np.transpose(img, (2, 0, 1))\n","img = np.reshape(img, (1, 3, 256, 256))\n","img = torch.FloatTensor(img).to(device)\n","with torch.no_grad():\n","  output = net(img)[0].cpu().numpy()\n","  c, h, w = output.shape\n","  y = np.zeros((h,w)).astype('uint8')\n","  for i in range(N_CLASS):\n","      mask = output[i]>0.7\n","      y[mask] = i\n","  save_label(y, './london.png')"],"execution_count":0,"outputs":[]}]}